{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP70ziwRqbGG0gHGsyjOaYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-515/tts_finetuned_model/blob/main/final_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introduction: Overview of TTS, its Applications, and the Importance of Fine-Tuning**\n",
        "\n",
        "---\n",
        "\n",
        "#### **Text-to-Speech (TTS) Overview**\n",
        "\n",
        "Text-to-Speech (TTS) systems are a branch of artificial intelligence that convert written text into spoken words, mimicking human speech. TTS technology has evolved significantly in recent years, benefiting from advancements in deep learning and natural language processing (NLP). Modern TTS models, such as SpeechT5, utilize large-scale neural networks to generate highly natural and expressive speech from a wide variety of text inputs.\n",
        "\n",
        "The core functionality of TTS involves several key processes:\n",
        "- **Text Analysis**: Breaking down the input text into smaller units like words and phrases.\n",
        "- **Linguistic Processing**: Generating a phonetic representation or speech sounds from the text, based on language rules.\n",
        "- **Waveform Generation**: Producing a human-like audio waveform that corresponds to the input text, based on phonetic and prosodic (intonation, rhythm) features.\n",
        "\n",
        "#### **Applications of TTS**\n",
        "\n",
        "TTS technology has a broad range of applications across different industries. Some of the most prominent uses include:\n",
        "\n",
        "- **Assistive Technology**: TTS is commonly used in screen readers for visually impaired individuals, providing them with audible access to digital content, including websites, e-books, and documents.\n",
        "- **Virtual Assistants**: Popular voice-based assistants like Amazon Alexa, Google Assistant, and Apple’s Siri rely on TTS to deliver responses to user queries in a conversational tone.\n",
        "- **Automated Customer Service**: TTS is used in call centers and interactive voice response (IVR) systems to provide customer support without human intervention.\n",
        "- **Language Learning**: TTS helps learners practice pronunciation and listen to native-like speech examples, improving their language acquisition.\n",
        "- **Audiobooks and Media**: TTS allows publishers to generate audiobook versions of written content, increasing accessibility and engagement with books, articles, and news reports.\n",
        "\n",
        "#### **Importance of Fine-Tuning**\n",
        "\n",
        "While pre-trained TTS models like SpeechT5 provide high-quality speech synthesis for general text, domain-specific applications often require fine-tuning to achieve optimal performance. Fine-tuning is the process of taking a pre-trained model and further training it on a smaller, specialized dataset to adapt it to a particular task or set of vocabulary.\n",
        "\n",
        "In this project, fine-tuning was essential for improving the TTS model’s pronunciation of technical terms, particularly in fields such as technology, engineering, and mathematics. The standard model may struggle with accurately pronouncing specialized vocabulary or phrases that are not common in general speech data. Fine-tuning the model on a dataset containing technical terms allows it to:\n",
        "\n",
        "- **Improve Pronunciation**: Correctly pronouncing complex domain-specific words or acronyms.\n",
        "- **Enhance Naturalness**: Ensure that the speech generated sounds fluent and natural, even with unfamiliar words.\n",
        "- **Increase Accuracy**: Reduce word error rates (WER) and improve the overall intelligibility of the generated speech.\n",
        "\n",
        "By fine-tuning SpeechT5, the model becomes better equipped to handle niche vocabulary, making it more suitable for applications like technical tutorials, educational content, and automated customer service in specific industries."
      ],
      "metadata": {
        "id": "jcHbaIgpehgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Methodology: Detailed Steps for Model Selection, Dataset Preparation, and Fine-Tuning**\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Model Selection**\n",
        "\n",
        "For this project, I chose the **SpeechT5** model, a state-of-the-art Text-to-Speech (TTS) transformer-based model developed by Microsoft and available on Hugging Face. The model was selected for its ability to generate high-quality speech across various applications and its capacity for fine-tuning on specific tasks. SpeechT5 offers flexibility in handling both general speech and more specialized domains, such as technical terms or regional languages.\n",
        "\n",
        "The selection criteria included:\n",
        "- **High performance on general TTS tasks**.\n",
        "- **Availability of pre-trained models** that could be fine-tuned for specific tasks.\n",
        "- **Support for both text-to-speech and speech-to-text tasks**, making it versatile for future expansion.\n",
        "- **Open-source availability on Hugging Face**, with active community support and resources for fine-tuning.\n",
        "\n",
        "#### **2. Dataset Preparation**\n",
        "\n",
        "I prepared two datasets for fine-tuning SpeechT5:\n",
        "- **English technical terms [dataset](https://huggingface.co/datasets/Yassmen/TTS_English_Technical_data)**.\n",
        "- **Hindi regional language [dataset](https://huggingface.co/datasets/1rsh/tts-rj-hi-karya)** for text-to-speech tasks.\n",
        "\n",
        "##### **Dataset Collection:**\n",
        "I sourced these datasets using Hugging Face's extensive library, which offers a range of publicly available datasets. The English dataset was specifically focused on technical terms from fields such as technology, science, and engineering. The Hindi dataset consisted of general and domain-specific words commonly used in regional contexts.\n",
        "\n",
        "##### **Data Cleaning and Preprocessing:**\n",
        "To ensure the data was suitable for model training, I performed the following preprocessing steps:\n",
        "- **Text Cleaning**: Removed special characters, punctuation, and unnecessary symbols to standardize the text data.\n",
        "- **Normalization**: Converted all text to lowercase (for English) and applied necessary transformations for Hindi.\n",
        "- **Audio Processing**: Audio files were standardized to a 16kHz sampling rate, and noise reduction techniques were applied to improve clarity.\n",
        "\n",
        "#### **3. Fine-Tuning Process**\n",
        "\n",
        "Fine-tuning involved adjusting the pre-trained SpeechT5 model to better handle the unique characteristics of my datasets. Since the default model had been trained on general text data, I needed to adapt it to both the technical vocabulary in English and the nuances of the Hindi language.\n",
        "\n",
        "##### **Steps for Fine-Tuning**:\n",
        "1. **Hugging Face Integration**: I utilized Hugging Face’s library to load the pre-trained SpeechT5 model and the required datasets. The `transformers` library provided an easy-to-use interface for this process.\n",
        "   \n",
        "2. **Training Configuration**: I configured the model's hyperparameters, such as:\n",
        "   - Learning rate,\n",
        "   - Batch size,\n",
        "   - Epochs (the number of passes through the training data),\n",
        "   - Optimizer settings, based on the Hugging Face documentation and best practices for fine-tuning.\n",
        "   \n",
        "\n",
        "3. **Training the Model**: I ran the fine-tuning process using the selected datasets. This required significant computational power, and I leveraged cloud platforms like Google Colab for faster processing. The training process was monitored through loss metrics, validation scores, and audio output quality.\n",
        "   \n",
        "4. **Validation and Testing**: During training, I periodically evaluated the model using a validation dataset. I checked the model’s ability to accurately generate speech for unseen samples and adjusted the hyperparameters where necessary.\n",
        "\n",
        "##### **Learning Resources and Tools**:\n",
        "Throughout the fine-tuning process, I relied on various learning resources and tools, including:\n",
        "- **Hugging Face Documentation**: For understanding how to work with SpeechT5, transformers, and fine-tuning processes.\n",
        "- **YouTube Tutorials**: For practical guides and step-by-step explanations of TTS model fine-tuning.\n",
        "- **Google Search**: For quick problem-solving, error resolution, and exploring best practices.\n",
        "- **ChatGPT**: For real-time guidance, code generation, and troubleshooting issues in my workflow.\n",
        "- **GitHub and StackOverflow**: For community support, accessing relevant repositories, and resolving coding errors.\n",
        "- **Medium Articles**: For detailed write-ups and case studies on fine-tuning NLP and TTS models.\n",
        "\n",
        "#### **4. Tools and Platforms Used**\n",
        "- **Hugging Face**: For accessing pre-trained models, datasets, and community resources.\n",
        "- **Google Colab**: For running the fine-tuning process using cloud-based GPU support.\n",
        "- **GitHub**: For version control and collaborative work.\n",
        "- **ChatGPT**: For assistance in problem-solving and code generation.\n"
      ],
      "metadata": {
        "id": "Ndj3htzuemdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results: Objective and Subjective Evaluations for English Technical Speech and Regional Language (Hindi) Model**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Objective Evaluation**\n",
        "\n",
        "Objective evaluation typically involves quantitative metrics to measure the performance of a text-to-speech model. For this project, I focused on **Word Error Rate (WER)** and **Mean Opinion Score (MOS)** as key evaluation metrics.\n",
        "\n",
        "##### **1.1. Word Error Rate (WER)**\n",
        "WER is a common metric used to assess the accuracy of a TTS model. It measures the difference between the expected transcription of speech and the actual text produced by the TTS model.\n",
        "\n",
        "- **English Technical Speech:**\n",
        "   - The WER for the English technical terms model was **4.167%**, indicating a high degree of accuracy in pronouncing specialized terms. Errors occurred primarily with rare acronyms or highly domain-specific phrases that were less represented in the dataset.\n",
        "  \n",
        "- **Hindi Regional Language:**\n",
        "   - The WER for the Hindi model was **100%**, reflecting it can not generate words or sentences.\n",
        "\n",
        "##### **1.2. Mean Opinion Score (MOS)**\n",
        "MOS is a subjective metric where human listeners rate the naturalness and quality of synthesized speech on a scale of 1 to 5 (1 being poor, 5 being excellent). To obtain MOS, I conducted a small evaluation by asking a group of volunteers to rate the speech quality based on a set of test samples.\n",
        "\n",
        "- **English Technical Speech:**\n",
        "   - The MOS for the English technical speech model was **3.66/5**. Participants noted that the pronunciation of most technical terms was accurate and natural, although some longer, complex sentences sounded slightly robotic.\n",
        "\n",
        "- **Hindi Regional Language:**\n",
        "   - The MOS for the Hindi model was **0/5**. Listeners found the speech full of noise can not able to hear any word or sentence.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Subjective Evaluation**\n",
        "\n",
        "Subjective evaluation involves a qualitative assessment of how well the model performed in real-world use cases. This includes feedback on naturalness, fluency, and intelligibility. Here’s the breakdown of subjective observations for both tasks:\n",
        "\n",
        "##### **2.1. English Technical Speech**\n",
        "\n",
        "The fine-tuned model on English technical terms was tested with domain-specific vocabulary, focusing on computer science, engineering, and mathematics. Here are some key observations:\n",
        "\n",
        "- **Accuracy of Technical Terms**: The model was able to correctly pronounce the majority of technical terms, including acronyms like \"GPU\" and \"API\", \"TTS\",\"CUDA\" etc. This is a significant improvement over the base model, which struggled with these terms.\n",
        "  \n",
        "- **Intonation and Emphasis**: The model successfully placed emphasis on key terms within technical phrases, improving the clarity and naturalness of speech. However, in longer sentences and some words like \"\"HTTP\", \"OAuth\", the intonation occasionally felt flat or mechanical, which might be due to the structure of the dataset or the complexity of certain phrases.\n",
        "\n",
        "- **Fluency**: For shorter, domain-specific terms, the speech was fluent and easy to understand. In complex sentences or paragraphs, there were occasional hesitations, but they were not frequent enough to significantly affect overall intelligibility.\n",
        "\n",
        "##### **2.2. Hindi Regional Language**\n",
        "\n",
        "The Hindi model was tested with general speech and domain-specific words from common regional vocabulary and it generated only the mechanical noises. So the observations include:\n",
        "\n",
        "- **Natural Pronunciation**: None\n",
        "  \n",
        "- **Dialectal Variations**: None\n",
        "\n",
        "- **Handling of Complex Words**: None\n",
        "---\n",
        "\n",
        "### **Final Summary of Results**\n",
        "\n",
        "- **Objective Results**:\n",
        "   - **English Technical Speech**: WER of **4.167%** and MOS of **3.66/5**.\n",
        "   - **Hindi Regional Language**: WER of **100%** and MOS of **0/5**.\n",
        "\n",
        "- **Subjective Results**:\n",
        "   - **English Technical Speech**: Good accuracy on technical terms, with minor issues in sentence-level fluency.\n",
        "   - **Hindi Regional Language**: Generating only Noises.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lmmHzqWsgp8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Challenges: Issues Faced During the Process**\n",
        "\n",
        "---\n",
        "\n",
        "During the process of fine-tuning the SpeechT5 model, I encountered several challenges, particularly related to dataset availability, code implementation, and handling the nuances of regional language processing. Below is a breakdown of the key challenges faced:\n",
        "\n",
        "#### **1. Dataset Availability and Preparation**\n",
        "\n",
        "Finding suitable datasets for fine-tuning the model was one of the most significant hurdles. While datasets for English technical terms were relatively easier to locate, identifying high-quality data for the **Hindi regional language** proved more difficult.\n",
        "\n",
        "- **Regional Language Dataset**: I initially struggled with creating my own dataset for Hindi, as I wasn’t entirely sure how to structure it properly for TTS training. Building an accurate and balanced dataset requires expertise in dataset curation, which I found challenging as a beginner. After extensive searching, I eventually found a suitable dataset on Hugging Face, but this took considerable time.\n",
        "  \n",
        "- **English Dataset**: Although datasets for technical terms in English were easier to access, ensuring that the dataset covered a wide enough variety of technical vocabulary was still a concern. I had to ensure that the dataset contained sufficient examples of the specialized terms I was targeting.\n",
        "\n",
        "#### **2. Understanding the Code and Model Implementation**\n",
        "\n",
        "As someone still in the learning phase, **understanding the fine-tuning code** and how to effectively implement the SpeechT5 model took longer than expected. Despite having a pre-trained model available, configuring the code for my specific tasks involved many trial-and-error attempts. It was a steep learning curve to:\n",
        "- Properly configure training parameters like batch size, learning rate, and number of epochs.\n",
        "- Ensure the data was correctly preprocessed and passed into the model.\n",
        "\n",
        "This process took several hours of debugging and refining, especially when trying to align the Hugging Face documentation and tutorials with my specific use case.\n",
        "\n",
        "#### **3. Resource Availability**\n",
        "\n",
        "Finding the right resources, including detailed tutorials, practical examples, and guidance for fine-tuning SpeechT5 on specific tasks, was not straightforward. I had to rely on a combination of:\n",
        "- **YouTube tutorials**,\n",
        "- **Documentation**,\n",
        "- **Google searches**,\n",
        "- **Community forums like StackOverflow**.\n",
        "\n",
        "This lack of readily available structured resources slowed down the process of building my project, particularly as the regional language model required more niche expertise.\n",
        "\n",
        "#### **4. Model Performance: English vs. Regional Language**\n",
        "\n",
        "- **English Model**: The fine-tuned model for English technical terms performed relatively well. The Word Error Rate (WER) was low, and the generated speech was mostly accurate, which was encouraging. The challenge here was mainly in selecting a dataset that comprehensively covered enough technical terminology to ensure good performance.\n",
        "\n",
        "- **Hindi Model**: The model for the Hindi regional language, however, **did not produce fully satisfactory results**. There were several challenges in handling the phonetics and linguistic nuances of Hindi:\n",
        "   - The Hindi dataset was less diverse than the English one, which led to **pronunciation errors** and issues in generating natural-sounding speech.\n",
        "   - Some regional words were difficult for the model to pronounce correctly, likely due to their infrequent representation in the training data.\n",
        "   - **Data preprocessing for Hindi** was more challenging because of the language's complexity, requiring extra care in normalizing the text and audio data for model consumption.\n",
        "\n",
        "#### **5. Data Processing for Hindi**\n",
        "\n",
        "Processing the Hindi dataset presented unique challenges:\n",
        "- **Text Preprocessing**: Hindi, being a complex language with various dialects, required careful handling to ensure consistency in the dataset. Normalizing the text and managing special characters and diacritics took extra effort.\n",
        "- **Audio Data**: Matching the corresponding audio files to the text for training required more manual intervention, as there were inconsistencies in the data that needed to be addressed before training could begin.\n",
        "\n",
        "---\n",
        "\n",
        "These challenges slowed down the development process but provided valuable learning experiences in working with different languages and handling complex datasets. Overcoming them required persistence, extensive use of available resources, and a willingness to learn from mistakes during model implementation and fine-tuning."
      ],
      "metadata": {
        "id": "qnzEBBU_jWwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion: Key Findings and Future Improvements**\n",
        "\n",
        "---\n",
        "\n",
        "#### **Summary of Findings**\n",
        "\n",
        "This project aimed to fine-tune the SpeechT5 model for two specific tasks:\n",
        "1. **English Technical Speech**, which focused on accurately pronouncing domain-specific terms from fields like technology and science.\n",
        "2. **Hindi Regional Language Speech**, which targeted generating natural-sounding speech in a regional language.\n",
        "\n",
        "After completing the fine-tuning process and evaluating the model’s performance, several key findings emerged:\n",
        "\n",
        "- **English Model Performance**: The fine-tuned SpeechT5 model performed well for English technical terms, with a low Word Error Rate (WER) of **4.167%** and a high Mean Opinion Score (MOS) of **3.16/5**. It handled specialized vocabulary effectively, demonstrating its suitability for technical fields.\n",
        "\n",
        "- **Hindi Model Performance**: While the Hindi model showed absolute disaster with a WER of **100%** and a MOS of **0/5**, the results were not satisfactory compared to the English model as hindi model was only consider of noise.\n",
        "\n",
        "- **Challenges**: Several challenges were faced throughout the project, including difficulties in dataset collection (especially for the Hindi language), understanding the code, and preprocessing data. These challenges highlighted the importance of proper dataset preparation and the complexities of working with regional languages.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Key Takeaways**\n",
        "\n",
        "- **Dataset Quality Matters**: The success of fine-tuning highly depends on the quality and diversity of the dataset. In this project, the Hindi dataset’s limited diversity impacted the overall model performance, while the English dataset, which had better representation of technical terms, led to stronger results.\n",
        "  \n",
        "- **Fine-Tuning Enhances Specificity**: Fine-tuning a pre-trained TTS model like SpeechT5 is highly effective for improving its performance on specialized tasks. In this case, the model's ability to accurately generate speech for technical terms improved significantly after fine-tuning.\n",
        "\n",
        "- **Complexity of Regional Languages**: Handling regional languages like Hindi, which has many dialectal variations and phonetic complexities, requires more robust data preprocessing and a carefully curated dataset to ensure natural and accurate speech generation.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Future Improvements**\n",
        "\n",
        "To build on the results and address the challenges, several areas of improvement can be pursued in future work:\n",
        "\n",
        "1. **Enhanced Dataset Collection for Hindi**: A larger, more diverse dataset covering different dialects and complex regional words is essential for improving the model’s performance on Hindi speech generation. Collaborative efforts or crowd-sourced datasets could help achieve this.\n",
        "\n",
        "2. **Advanced Data Augmentation Techniques**: Applying advanced data augmentation techniques, such as speech synthesis or back-translation for underrepresented words, can help expand the dataset and improve the model's ability to handle diverse pronunciations and accents.\n",
        "\n",
        "3. **Model Optimization for Regional Languages**: Further fine-tuning with more specific hyperparameters or specialized models that focus on regional language processing could yield better results for languages like Hindi. Exploring other architectures or transfer learning approaches might also be beneficial.\n",
        "\n",
        "4. **Expanded Evaluation Metrics**: In addition to WER and MOS, incorporating more comprehensive evaluation metrics like Character Error Rate (CER) and linguistic accuracy could provide deeper insights into the model's strengths and weaknesses across both languages.\n",
        "\n",
        "5. **Experimenting with Training Hyperparameters**: Another potential area for improvement is **experimenting with training hyperparameters**. Fine-tuning hyperparameters such as **learning rate, batch size, number of epochs**, and **optimizer selection** can significantly impact model performance. During this project, I used standard hyperparameters, but future experimentation with different values could help achieve better convergence, especially for the regional language model. Additionally, techniques like **learning rate scheduling** and **early stopping** could be applied to prevent overfitting and improve the overall robustness of the model, particularly for handling complex or underrepresented data points.\n",
        "\n",
        "---\n",
        "\n",
        "Overall, this project demonstrated the potential of fine-tuning a transformer-based TTS model like SpeechT5 for specific use cases. While the English model performed admirably, further work is needed to bring the Hindi model up to the same standard. The lessons learned from this project can guide future efforts to improve TTS models for both technical and regional language applications."
      ],
      "metadata": {
        "id": "r_7VrT7SufvY"
      }
    }
  ]
}