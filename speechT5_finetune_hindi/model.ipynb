{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCL0jKxQmqDswOr/qny51i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "291895c0728d4b15a3118210a814c4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03f1b62dff3e48faa2213eb4bae1f32f",
              "IPY_MODEL_6ff4f9f3328d4bcdb85d9a3a12022077",
              "IPY_MODEL_efa8a3a1596c4646b34b4f8adbb25264"
            ],
            "layout": "IPY_MODEL_b0a816e79043439682488275247c59cf"
          }
        },
        "03f1b62dff3e48faa2213eb4bae1f32f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_873282cea74a41f9be2d846873699afe",
            "placeholder": "​",
            "style": "IPY_MODEL_8c019a830223456fab9769532a44a4ff",
            "value": "Map: 100%"
          }
        },
        "6ff4f9f3328d4bcdb85d9a3a12022077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0faf0b115b724024abf77a25512784fc",
            "max": 12074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32d1b61e5b9f4562bff4023eb5e7da63",
            "value": 12074
          }
        },
        "efa8a3a1596c4646b34b4f8adbb25264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d84bd35cba834c409da074b808361068",
            "placeholder": "​",
            "style": "IPY_MODEL_cb7a6fbb609c4875b6925f8ad0d90a84",
            "value": " 12074/12074 [00:00&lt;00:00, 110304.30 examples/s]"
          }
        },
        "b0a816e79043439682488275247c59cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873282cea74a41f9be2d846873699afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c019a830223456fab9769532a44a4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0faf0b115b724024abf77a25512784fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d1b61e5b9f4562bff4023eb5e7da63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d84bd35cba834c409da074b808361068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7a6fbb609c4875b6925f8ad0d90a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-515/tts_finetuned_model/blob/main/speechT5_finetune_hindi/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7bfcV6dNFtM"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets soundfile accelerate speechbrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "jeYqyzBvNPkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
        "\n",
        "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")"
      ],
      "metadata": {
        "id": "U5GSZgTSNrSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Audio\n",
        "\n",
        "dataset = load_dataset(\"1rsh/tts-rj-hi-karya\")"
      ],
      "metadata": {
        "id": "B219IWt6RN-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zrtULCE-0yae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset['train']"
      ],
      "metadata": {
        "id": "rR6yXWzQ25ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "5_U-RHdZ6772"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "half_size = len(dataset) // 35\n",
        "dataset = dataset.select(range(half_size))\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9vKYY_w4DCm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "id": "mt5Irin3DzbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5Processor\n",
        "\n",
        "model_name = \"microsoft/speecht5_tts\"\n",
        "processor = SpeechT5Processor.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "tuQeGqkhD5g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = processor.tokenizer"
      ],
      "metadata": {
        "id": "Ea8dKIMRFuRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2:5]"
      ],
      "metadata": {
        "id": "KRo2kj77F5Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "    all_text = \" \".join(batch[\"sentence\"])\n",
        "    vocab = list(set(all_text))\n",
        "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "\n",
        "vocabs = dataset.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=dataset.column_names,\n",
        ")\n",
        "\n",
        "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
        "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "291895c0728d4b15a3118210a814c4dd",
            "03f1b62dff3e48faa2213eb4bae1f32f",
            "6ff4f9f3328d4bcdb85d9a3a12022077",
            "efa8a3a1596c4646b34b4f8adbb25264",
            "b0a816e79043439682488275247c59cf",
            "873282cea74a41f9be2d846873699afe",
            "8c019a830223456fab9769532a44a4ff",
            "0faf0b115b724024abf77a25512784fc",
            "32d1b61e5b9f4562bff4023eb5e7da63",
            "d84bd35cba834c409da074b808361068",
            "cb7a6fbb609c4875b6925f8ad0d90a84"
          ]
        },
        "id": "McdP-lXvGJ-M",
        "outputId": "1a346c8e-5436-4c31-d4a7-9f1e6d17df98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12074 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "291895c0728d4b15a3118210a814c4dd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vocab - tokenizer_vocab"
      ],
      "metadata": {
        "id": "zvTkgijwGOz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\u0900-\\u097F\\s\\']', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Define a function to add the normalized_text column\n",
        "def add_normalized_text(example):\n",
        "    example['normalized_text'] = normalize_text(example['sentence'])\n",
        "    return example\n",
        "\n",
        "# Apply the function to the dataset\n",
        "dataset = dataset.map(add_normalized_text)\n",
        "\n",
        "# Print the first few examples to verify\n",
        "print(dataset[2:5])"
      ],
      "metadata": {
        "id": "qw2Fe-sXGRjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_all_chars(batch):\n",
        "    all_text = \" \".join(batch[\"normalized_text\"])\n",
        "    vocab = list(set(all_text))\n",
        "    return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
        "\n",
        "\n",
        "vocabs = dataset.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=dataset.column_names,\n",
        ")\n",
        "\n",
        "dataset_vocab = set(vocabs[\"vocab\"][0])\n",
        "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
      ],
      "metadata": {
        "id": "D4qd2syuGV0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_symbols = ['४', '५', '६','७']\n",
        "dataset_vocab.update(new_symbols)"
      ],
      "metadata": {
        "id": "MbvjdRuYo4J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vocab - tokenizer_vocab"
      ],
      "metadata": {
        "id": "NF0Oq5L-GeyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replacements = {\n",
        "    ('ँ', 'n'),   # Anusvara (nasal sound)\n",
        "    ('ं', 'n'),   # Anusvara (nasal sound)\n",
        "    ('ः', 'h'),   # Visarga (aspirated sound)\n",
        "    ('अ', 'uh'),\n",
        "    ('आ', 'aa'),\n",
        "    ('इ', 'i'),\n",
        "    ('ई', 'ee'),\n",
        "    ('उ', 'u'),\n",
        "    ('ऊ', 'oo'),\n",
        "    ('ऋ', 'ri'),\n",
        "    ('ऍ', 'ae'),\n",
        "    ('ए', 'e'),\n",
        "    ('ऐ', 'ai'),\n",
        "    ('ऑ', 'aw'),\n",
        "    ('ओ', 'o'),\n",
        "    ('औ', 'au'),\n",
        "    ('क', 'k'),\n",
        "    ('ख', 'kh'),\n",
        "    ('ग', 'g'),\n",
        "    ('घ', 'gh'),\n",
        "    ('च', 'ch'),\n",
        "    ('छ', 'chh'),\n",
        "    ('ज', 'j'),\n",
        "    ('झ', 'jh'),\n",
        "    ('ञ', 'ny'),\n",
        "    ('ट', 't'),\n",
        "    ('ठ', 'th'),\n",
        "    ('ड', 'd'),\n",
        "    ('ढ', 'dh'),\n",
        "    ('ण', 'n'),\n",
        "    ('त', 't'),\n",
        "    ('थ', 'th'),\n",
        "    ('द', 'd'),\n",
        "    ('ध', 'dh'),\n",
        "    ('न', 'n'),\n",
        "    ('प', 'p'),\n",
        "    ('फ', 'ph'),\n",
        "    ('ब', 'b'),\n",
        "    ('भ', 'bh'),\n",
        "    ('म', 'm'),\n",
        "    ('य', 'y'),\n",
        "    ('र', 'r'),\n",
        "    ('ल', 'l'),\n",
        "    ('व', 'v'),\n",
        "    ('श', 'sh'),\n",
        "    ('ष', 'shh'),\n",
        "    ('स', 's'),\n",
        "    ('ह', 'h'),\n",
        "    ('़', ''),    # Nukta (diacritic mark for foreign sounds)\n",
        "    ('ा', 'aa'),  # Vowel sound modifier\n",
        "    ('ि', 'i'),   # Vowel sound modifier\n",
        "    ('ी', 'ee'),  # Vowel sound modifier\n",
        "    ('ु', 'u'),   # Vowel sound modifier\n",
        "    ('ू', 'oo'),  # Vowel sound modifier\n",
        "    ('ृ', 'ri'),  # Vowel sound modifier\n",
        "    ('े', 'e'),   # Vowel sound modifier\n",
        "    ('ै', 'ai'),  # Vowel sound modifier\n",
        "    ('ॉ', 'aw'),  # Vowel sound modifier\n",
        "    ('ो', 'o'),   # Vowel sound modifier\n",
        "    ('ौ', 'au'),  # Vowel sound modifier\n",
        "    ('्', ''),    # Halant (for stopping consonant sound)\n",
        "    ('क़', 'q'),\n",
        "    ('ख़', 'kh'),\n",
        "    ('ग़', 'gh'),\n",
        "    ('ज़', 'z'),\n",
        "    ('ड़', 'r'),\n",
        "    ('ढ़', 'rh'),\n",
        "    ('फ़', 'f'),\n",
        "    ('ॠ', 'rri'),\n",
        "    ('।', 'period'),  # Purnavirama (full stop)\n",
        "    ('०', '0'),\n",
        "    ('१', '1'),\n",
        "    ('२', '2'),\n",
        "    ('३', '3'),\n",
        "    ('४', '4'),\n",
        "    ('५', '5'),\n",
        "    ('६', '6'),\n",
        "    ('७', '7'),\n",
        "    ('८', '8'),\n",
        "    ('९', '9')\n",
        "}"
      ],
      "metadata": {
        "id": "8uNNi8vWNKuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup_text(inputs):\n",
        "    for src, dst in replacements:\n",
        "        inputs[\"normalized_text\"] = inputs[\"normalized_text\"].replace(src, dst)\n",
        "    return inputs\n",
        "\n",
        "dataset = dataset.map(cleanup_text)"
      ],
      "metadata": {
        "id": "S0S3BoEnr8kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from speechbrain.pretrained import EncoderClassifier\n",
        "\n",
        "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "speaker_model = EncoderClassifier.from_hparams(\n",
        "    source=spk_model_name,\n",
        "    run_opts={\"device\": device},\n",
        "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
        ")\n",
        "\n",
        "\n",
        "def create_speaker_embedding(waveform):\n",
        "    with torch.no_grad():\n",
        "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
        "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
        "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
        "    return speaker_embeddings"
      ],
      "metadata": {
        "id": "hroLQNHFs9wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(example):\n",
        "    audio = example[\"audio\"]\n",
        "\n",
        "    example = processor(\n",
        "        text=example[\"normalized_text\"],\n",
        "        audio_target=audio[\"array\"],\n",
        "        sampling_rate=audio[\"sampling_rate\"],\n",
        "        return_attention_mask=False,\n",
        "    )\n",
        "\n",
        "    # strip off the batch dimension\n",
        "    example[\"labels\"] = example[\"labels\"][0]\n",
        "\n",
        "    # use SpeechBrain to obtain x-vector\n",
        "    example[\"speaker_embeddings\"] = create_speaker_embedding(audio[\"array\"])\n",
        "\n",
        "    return example"
      ],
      "metadata": {
        "id": "Mr58YgMGxJx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_example = prepare_dataset(dataset[0])\n",
        "list(processed_example.keys())"
      ],
      "metadata": {
        "id": "dPXvo8e4xNOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_example[\"speaker_embeddings\"].shape"
      ],
      "metadata": {
        "id": "xZqzYtauxQIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)"
      ],
      "metadata": {
        "id": "jFo2Iy6sxSsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_not_too_long(input_ids):\n",
        "    input_length = len(input_ids)\n",
        "    return input_length < 200\n",
        "\n",
        "dataset = dataset.filter(is_not_too_long, input_columns=[\"input_ids\"])\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "F_Uhc_uixVUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "id": "scJ8XJ9K4N99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TTSDataCollatorWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(\n",
        "        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        input_ids = [{\"input_ids\": feature[\"input_ids\"]} for feature in features]\n",
        "        label_features = [{\"input_values\": feature[\"labels\"]} for feature in features]\n",
        "        speaker_features = [feature[\"speaker_embeddings\"] for feature in features]\n",
        "\n",
        "        # collate the inputs and targets into a batch\n",
        "        batch = processor.pad(\n",
        "            input_ids=input_ids, labels=label_features, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        batch[\"labels\"] = batch[\"labels\"].masked_fill(\n",
        "            batch.decoder_attention_mask.unsqueeze(-1).ne(1), -100\n",
        "        )\n",
        "\n",
        "        # not used during fine-tuning\n",
        "        del batch[\"decoder_attention_mask\"]\n",
        "\n",
        "        # round down target lengths to multiple of reduction factor\n",
        "        if model.config.reduction_factor > 1:\n",
        "            target_lengths = torch.tensor(\n",
        "                [len(feature[\"input_values\"]) for feature in label_features]\n",
        "            )\n",
        "            target_lengths = target_lengths.new(\n",
        "                [\n",
        "                    length - length % model.config.reduction_factor\n",
        "                    for length in target_lengths\n",
        "                ]\n",
        "            )\n",
        "            max_length = max(target_lengths)\n",
        "            batch[\"labels\"] = batch[\"labels\"][:, :max_length]\n",
        "\n",
        "        # also add in the speaker embeddings\n",
        "        batch[\"speaker_embeddings\"] = torch.tensor(speaker_features)\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "uz_YItuq4hHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = TTSDataCollatorWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "_NK6Wf0U5Hp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5ForTextToSpeech\n",
        "\n",
        "model = SpeechT5ForTextToSpeech.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "iXL58YgG5MJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"speecht5_finetuned_rohit_hindi\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=100,\n",
        "    max_steps=800,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=2,\n",
        "    save_steps=100,\n",
        "    eval_steps=100,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    greater_is_better=False,\n",
        "    label_names=[\"labels\"],\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "G-40cYUN8DPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=processor,\n",
        ")"
      ],
      "metadata": {
        "id": "w71J7LwQD-EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "N9XLEkI4D--r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "FlqJoUt6EBN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SpeechT5ForTextToSpeech.from_pretrained(\n",
        "    \"speecht5_finetuned_rohit_hindi\"\n",
        ")"
      ],
      "metadata": {
        "id": "cmPELcDVEGxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset[\"test\"][304]\n",
        "speaker_embeddings = torch.tensor(example[\"speaker_embeddings\"]).unsqueeze(0)"
      ],
      "metadata": {
        "id": "fwhq6M0DELZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"मुझे सुबह ७ बजे उठना है, मेरे पास २ किताबें हैं।\""
      ],
      "metadata": {
        "id": "mGkvauTtET1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-num2words\n",
        "\n",
        "from num_to_words import num_to_word\n",
        "\n",
        "import re\n",
        "\n",
        "def replace_numbers_with_words(text):\n",
        "    def replace(match):\n",
        "        number = int(match.group())\n",
        "        return number_to_word(number, lang='hi')\n",
        "\n",
        "    result = re.sub(r'\\b\\d+\\b', replace, text)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "80NsnZ2lGVth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean up text using the replacement pairs\n",
        "def cleanup_text(text):\n",
        "    for src, dst in replacements:\n",
        "        text = text.replace(src, dst)\n",
        "    return text"
      ],
      "metadata": {
        "id": "3woKmA-aIX5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converted_text = replace_numbers_with_words(text)\n",
        "cleaned_text = cleanup_text(converted_text)\n",
        "final_text = normalize_text(cleaned_text)\n",
        "final_text"
      ],
      "metadata": {
        "id": "WHZbxInJIcAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(text=final_text, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "pcf076OgIdI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SpeechT5HifiGan\n",
        "\n",
        "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
        "speech = model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder)"
      ],
      "metadata": {
        "id": "PH8s1g6eIgD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "import soundfile as sf\n",
        "\n",
        "Audio(speech.numpy(), rate=16000)"
      ],
      "metadata": {
        "id": "0PeN6QIPIh8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the audio to a file (e.g., 'output.wav')\n",
        "sf.write('output.wav', speech.numpy(), 16000)"
      ],
      "metadata": {
        "id": "rxP6w9QaI4Yh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}